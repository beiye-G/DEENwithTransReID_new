[2023-11-16 12:45:32] ==========
Args:Namespace(arch='resnet50', batch_size=8, dataset='sysu', erasing_p=0.5, gpu='4', img_h=256, img_w=128, lambda_1=0.8, lambda_2=0.01, log_path='log/', lr=0.001, margin=0.3, mode='all', model_path='save_model/', num_pos=4, optim='AdamW', resume='sysu_deen_p4_n6_lr_0.1_seed_0_best.t', save_epoch=20, seed=0, stride=16, test_batch=4, test_only=False, trial=2, vis_log_path='log/vis_log/', workers=4)
==========[2023-11-16 12:45:32] 
[2023-11-16 12:45:32] ==> Loading data..[2023-11-16 12:45:32] 
[2023-11-16 12:45:59] Dataset sysu statistics:[2023-11-16 12:45:59] 
[2023-11-16 12:45:59]   ------------------------------[2023-11-16 12:45:59] 
[2023-11-16 12:45:59]   subset   | # ids | # images[2023-11-16 12:45:59] 
[2023-11-16 12:45:59]   ------------------------------[2023-11-16 12:45:59] 
[2023-11-16 12:45:59]   visible  |   395 |    22258[2023-11-16 12:45:59] 
[2023-11-16 12:45:59]   thermal  |   395 |    11909[2023-11-16 12:45:59] 
[2023-11-16 12:45:59]   ------------------------------[2023-11-16 12:45:59] 
[2023-11-16 12:45:59]   query    |    96 |     3803[2023-11-16 12:45:59] 
[2023-11-16 12:45:59]   gallery  |    96 |      301[2023-11-16 12:45:59] 
[2023-11-16 12:45:59]   ------------------------------[2023-11-16 12:45:59] 
[2023-11-16 12:45:59] Data Loading Time:	 26.909[2023-11-16 12:45:59] 
[2023-11-16 12:45:59] ==> Building model..[2023-11-16 12:45:59] 
[2023-11-16 12:47:02] using stride: 16, and patch number is num_y16 * num_x8[2023-11-16 12:47:02] 
[2023-11-16 12:47:03] using drop_out rate is : 0.0[2023-11-16 12:47:03] 
[2023-11-16 12:47:03] using attn_drop_out rate is : 0.0[2023-11-16 12:47:03] 
[2023-11-16 12:47:03] using drop_path rate is : 0.1[2023-11-16 12:47:03] 
[2023-11-16 12:47:04] Load 1 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 2 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 3 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 4 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 5 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 6 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 7 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 8 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 9 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 10 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 11 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 12 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 13 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 14 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 15 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 16 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 17 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 18 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 19 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 20 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 21 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 22 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 23 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 24 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 25 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 26 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 27 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 28 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 29 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 30 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 31 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 32 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 33 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 34 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 35 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 36 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 37 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 38 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 39 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 40 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 41 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 42 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 43 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 44 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 45 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 46 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 47 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 48 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 49 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 50 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 51 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 52 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 53 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 54 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 55 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 56 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 57 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 58 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 59 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 60 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 61 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:04] Load 62 / 156 layers.[2023-11-16 12:47:04] 
[2023-11-16 12:47:05] Load 63 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 64 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 65 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 66 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 67 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 68 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 69 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 70 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 71 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 72 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 73 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 74 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 75 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 76 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 77 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 78 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 79 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 80 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 81 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 82 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 83 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 84 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 85 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 86 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 87 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 88 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 89 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 90 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 91 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 92 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 93 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 94 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 95 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 96 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 97 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 98 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 99 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 100 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 101 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 102 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 103 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 104 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 105 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 106 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 107 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 108 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 109 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 110 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 111 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 112 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 113 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 114 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 115 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 116 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 117 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 118 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 119 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 120 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 121 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 122 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 123 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 124 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 125 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 126 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 127 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 128 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 129 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 130 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 131 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 132 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 133 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 134 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 135 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 136 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 137 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 138 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 139 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 140 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 141 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 142 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 143 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 144 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 145 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 146 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 147 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Resized position embedding from size:torch.Size([1, 197, 768]) to size: torch.Size([1, 129, 768]) with height:16 width: 8[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 148 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 149 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] Load 150 / 156 layers.[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] 152[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] odict_keys(['cls_token', 'norm.bias', 'norm.weight', 'blocks.0.norm1.bias', 'blocks.0.norm1.weight', 'blocks.0.norm2.bias', 'blocks.0.norm2.weight', 'blocks.0.mlp.fc1.bias', 'blocks.0.mlp.fc1.weight', 'blocks.0.mlp.fc2.bias', 'blocks.0.mlp.fc2.weight', 'blocks.0.attn.proj.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.qkv.weight', 'blocks.1.norm1.bias', 'blocks.1.norm1.weight', 'blocks.1.norm2.bias', 'blocks.1.norm2.weight', 'blocks.1.mlp.fc1.bias', 'blocks.1.mlp.fc1.weight', 'blocks.1.mlp.fc2.bias', 'blocks.1.mlp.fc2.weight', 'blocks.1.attn.proj.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.qkv.weight', 'blocks.10.norm1.bias', 'blocks.10.norm1.weight', 'blocks.10.norm2.bias', 'blocks.10.norm2.weight', 'blocks.10.mlp.fc1.bias', 'blocks.10.mlp.fc1.weight', 'blocks.10.mlp.fc2.bias', 'blocks.10.mlp.fc2.weight', 'blocks.10.attn.proj.bias', 'blocks.10.attn.proj.weight', 'blocks.10.attn.qkv.bias', 'blocks.10.attn.qkv.weight', 'blocks.11.norm1.bias', 'blocks.11.norm1.weight', 'blocks.11.norm2.bias', 'blocks.11.norm2.weight', 'blocks.11.mlp.fc1.bias', 'blocks.11.mlp.fc1.weight', 'blocks.11.mlp.fc2.bias', 'blocks.11.mlp.fc2.weight', 'blocks.11.attn.proj.bias', 'blocks.11.attn.proj.weight', 'blocks.11.attn.qkv.bias', 'blocks.11.attn.qkv.weight', 'blocks.2.norm1.bias', 'blocks.2.norm1.weight', 'blocks.2.norm2.bias', 'blocks.2.norm2.weight', 'blocks.2.mlp.fc1.bias', 'blocks.2.mlp.fc1.weight', 'blocks.2.mlp.fc2.bias', 'blocks.2.mlp.fc2.weight', 'blocks.2.attn.proj.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.qkv.weight', 'blocks.3.norm1.bias', 'blocks.3.norm1.weight', 'blocks.3.norm2.bias', 'blocks.3.norm2.weight', 'blocks.3.mlp.fc1.bias', 'blocks.3.mlp.fc1.weight', 'blocks.3.mlp.fc2.bias', 'blocks.3.mlp.fc2.weight', 'blocks.3.attn.proj.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.qkv.weight', 'blocks.4.norm1.bias', 'blocks.4.norm1.weight', 'blocks.4.norm2.bias', 'blocks.4.norm2.weight', 'blocks.4.mlp.fc1.bias', 'blocks.4.mlp.fc1.weight', 'blocks.4.mlp.fc2.bias', 'blocks.4.mlp.fc2.weight', 'blocks.4.attn.proj.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.qkv.weight', 'blocks.5.norm1.bias', 'blocks.5.norm1.weight', 'blocks.5.norm2.bias', 'blocks.5.norm2.weight', 'blocks.5.mlp.fc1.bias', 'blocks.5.mlp.fc1.weight', 'blocks.5.mlp.fc2.bias', 'blocks.5.mlp.fc2.weight', 'blocks.5.attn.proj.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.qkv.weight', 'blocks.6.norm1.bias', 'blocks.6.norm1.weight', 'blocks.6.norm2.bias', 'blocks.6.norm2.weight', 'blocks.6.mlp.fc1.bias', 'blocks.6.mlp.fc1.weight', 'blocks.6.mlp.fc2.bias', 'blocks.6.mlp.fc2.weight', 'blocks.6.attn.proj.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.qkv.weight', 'blocks.7.norm1.bias', 'blocks.7.norm1.weight', 'blocks.7.norm2.bias', 'blocks.7.norm2.weight', 'blocks.7.mlp.fc1.bias', 'blocks.7.mlp.fc1.weight', 'blocks.7.mlp.fc2.bias', 'blocks.7.mlp.fc2.weight', 'blocks.7.attn.proj.bias', 'blocks.7.attn.proj.weight', 'blocks.7.attn.qkv.bias', 'blocks.7.attn.qkv.weight', 'blocks.8.norm1.bias', 'blocks.8.norm1.weight', 'blocks.8.norm2.bias', 'blocks.8.norm2.weight', 'blocks.8.mlp.fc1.bias', 'blocks.8.mlp.fc1.weight', 'blocks.8.mlp.fc2.bias', 'blocks.8.mlp.fc2.weight', 'blocks.8.attn.proj.bias', 'blocks.8.attn.proj.weight', 'blocks.8.attn.qkv.bias', 'blocks.8.attn.qkv.weight', 'blocks.9.norm1.bias', 'blocks.9.norm1.weight', 'blocks.9.norm2.bias', 'blocks.9.norm2.weight', 'blocks.9.mlp.fc1.bias', 'blocks.9.mlp.fc1.weight', 'blocks.9.mlp.fc2.bias', 'blocks.9.mlp.fc2.weight', 'blocks.9.attn.proj.bias', 'blocks.9.attn.proj.weight', 'blocks.9.attn.qkv.bias', 'blocks.9.attn.qkv.weight', 'pos_embed', 'patch_embed.proj.bias', 'patch_embed.proj.weight', 'head.bias', 'head.weight'])[2023-11-16 12:47:05] 
[2023-11-16 12:47:05] odict_keys(['cls_token', 'pos_embed', 'patch_embed.proj.weight', 'patch_embed.proj.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.fc1.weight', 'blocks.0.mlp.fc1.bias', 'blocks.0.mlp.fc2.weight', 'blocks.0.mlp.fc2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.fc1.weight', 'blocks.1.mlp.fc1.bias', 'blocks.1.mlp.fc2.weight', 'blocks.1.mlp.fc2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.fc1.weight', 'blocks.2.mlp.fc1.bias', 'blocks.2.mlp.fc2.weight', 'blocks.2.mlp.fc2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.fc1.weight', 'blocks.3.mlp.fc1.bias', 'blocks.3.mlp.fc2.weight', 'blocks.3.mlp.fc2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.fc1.weight', 'blocks.4.mlp.fc1.bias', 'blocks.4.mlp.fc2.weight', 'blocks.4.mlp.fc2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.fc1.weight', 'blocks.5.mlp.fc1.bias', 'blocks.5.mlp.fc2.weight', 'blocks.5.mlp.fc2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.fc1.weight', 'blocks.6.mlp.fc1.bias', 'blocks.6.mlp.fc2.weight', 'blocks.6.mlp.fc2.bias', 'blocks.7.norm1.weight', 'blocks.7.norm1.bias', 'blocks.7.attn.qkv.weight', 'blocks.7.attn.qkv.bias', 'blocks.7.attn.proj.weight', 'blocks.7.attn.proj.bias', 'blocks.7.norm2.weight', 'blocks.7.norm2.bias', 'blocks.7.mlp.fc1.weight', 'blocks.7.mlp.fc1.bias', 'blocks.7.mlp.fc2.weight', 'blocks.7.mlp.fc2.bias', 'blocks.8.norm1.weight', 'blocks.8.norm1.bias', 'blocks.8.attn.qkv.weight', 'blocks.8.attn.qkv.bias', 'blocks.8.attn.proj.weight', 'blocks.8.attn.proj.bias', 'blocks.8.norm2.weight', 'blocks.8.norm2.bias', 'blocks.8.mlp.fc1.weight', 'blocks.8.mlp.fc1.bias', 'blocks.8.mlp.fc2.weight', 'blocks.8.mlp.fc2.bias', 'blocks.9.norm1.weight', 'blocks.9.norm1.bias', 'blocks.9.attn.qkv.weight', 'blocks.9.attn.qkv.bias', 'blocks.9.attn.proj.weight', 'blocks.9.attn.proj.bias', 'blocks.9.norm2.weight', 'blocks.9.norm2.bias', 'blocks.9.mlp.fc1.weight', 'blocks.9.mlp.fc1.bias', 'blocks.9.mlp.fc2.weight', 'blocks.9.mlp.fc2.bias', 'blocks.10.norm1.weight', 'blocks.10.norm1.bias', 'blocks.10.attn.qkv.weight', 'blocks.10.attn.qkv.bias', 'blocks.10.attn.proj.weight', 'blocks.10.attn.proj.bias', 'blocks.10.norm2.weight', 'blocks.10.norm2.bias', 'blocks.10.mlp.fc1.weight', 'blocks.10.mlp.fc1.bias', 'blocks.10.mlp.fc2.weight', 'blocks.10.mlp.fc2.bias', 'blocks.11.norm1.weight', 'blocks.11.norm1.bias', 'blocks.11.attn.qkv.weight', 'blocks.11.attn.qkv.bias', 'blocks.11.attn.proj.weight', 'blocks.11.attn.proj.bias', 'blocks.11.norm2.weight', 'blocks.11.norm2.bias', 'blocks.11.mlp.fc1.weight', 'blocks.11.mlp.fc1.bias', 'blocks.11.mlp.fc2.weight', 'blocks.11.mlp.fc2.bias', 'norm.weight', 'norm.bias', 'bottleneck.weight', 'bottleneck.bias', 'bottleneck.running_mean', 'bottleneck.running_var', 'bottleneck.num_batches_tracked', 'classifier.weight'])[2023-11-16 12:47:05] 
[2023-11-16 12:47:11] ==> no checkpoint found at sysu_deen_p4_n6_lr_0.1_seed_0_best.t[2023-11-16 12:47:11] 
[2023-11-16 12:47:11] ==> Start Training...[2023-11-16 12:47:11] 
[2023-11-16 12:47:11] ==> Preparing Data Loader...[2023-11-16 12:47:11] 
[2023-11-16 12:47:11] 0[2023-11-16 12:47:11] 
[2023-11-16 12:47:11] [20927 20945 20945 ...  6753  6784  6761][2023-11-16 12:47:11] 
[2023-11-16 12:47:11] [10597 10605 10597 ...  2900  2898  2916][2023-11-16 12:47:11] 
